{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U12 Abdullah Barhoum (5041774), Katharina MÃ¼ller (5284090)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 12\n",
    "\n",
    "In this tutorium, we will work on GANs networks (https://arxiv.org/pdf/1406.2661.pdf). This kind of network is part of the generative networks who are actually able to generate synthetic data. This network is actually composed of two, a generator responsible for generate fake data and a discriminator for investigating on the trueness of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:44:45.591000Z",
     "start_time": "2020-01-28T13:44:45.581028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://pathmind.com/images/wiki/GANs.png\" width=\"700\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://pathmind.com/images/wiki/GANs.png\", width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The disciminator can be see as a very simple fully connected network, composed of several layer of neurons and a simple output of one neurone who just determine if a image is true or false.\n",
    "\n",
    "The generator looks more like the upscaling part of the segmenetation network. A small piece of noise is injected and the output is an images. \n",
    "\n",
    "The training is maybe the most original part. \n",
    "\n",
    "First, you train the discriminator alone by injecting the training set (True data so label=True) and a set of data generated by the generator (label=False) you then have a loss to back propagate. *Applause, you trained you discriminator for one batch*\n",
    "\n",
    "Second, you inject some noise in your generator, the generator produce some fake images, you inject this fake images in you discriminator and use the labels generated by the discriminator to compute your backpropagation. So to train your generator, you will consider the generator and the discriminator as the same network, you just don't train the discriminator in this case.\n",
    "\n",
    "## 12.1\n",
    "\n",
    "We ask you then to program you own GANs. this network should be just compose of fully connected layer (no conv). You should define the architecture of the network, then provide two training function one for the generator and one for the discriminator and make him learn!\n",
    "\n",
    "We will take the MNIST dataset here for simplicity and lightness. The architecture I used was :\n",
    "\n",
    "G : (Input : random Tensor = 100) => (FC1 : fully connected = 256) => (BatchNormalisation) => (LeakyReLU) => (DropOut) => (FC2 : fully connected = 512) => (BatchNormalisation) => (LeakyReLU) => (DropOut) => (FC2 : fully connected = 784) =>  (Tanh)\n",
    "\n",
    "D : (Input : flatten images Tensor = 784) => (FC1 : fully connected = 1024) => (BatchNormalisation) => (LeakyReLU) => (DropOut) => (FC2 : fully connected = 512) => (BatchNormalisation) => (LeakyReLU) => (DropOut) => (FC2 : fully connected = 1) =>  (Sigmoid)\n",
    "\n",
    "This architecture is what I use, it's working but not great, so feel free to change it!!\n",
    "\n",
    "The training is 20-30min on a 1060 6Go for 100 epochs and batch size of 100. Here, it's a little bit different than before, the loss do not necessarly go done, it's a race between D and G so both cannot be good at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:39:16.235465Z",
     "start_time": "2020-01-29T09:39:11.249796Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T14:02:19.689446Z",
     "start_time": "2020-01-28T14:02:19.658251Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    MNIST(root='./data/', train=True, download=True, transform = T.Compose([\n",
    "        T.ToTensor(), \n",
    "        T.Normalize(mean=(0.5,), std=(0.5,))\n",
    "    ])),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T14:02:21.887756Z",
     "start_time": "2020-01-28T14:02:21.003946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_data, example_targets = next(iter(train_loader))\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T14:11:34.197974Z",
     "start_time": "2020-01-28T14:02:34.645176Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(-1, *self.shape)\n",
    "\n",
    "z_size = 49\n",
    "\n",
    "generator = nn.Sequential(\n",
    "    nn.Linear(z_size, 49 * 3),\n",
    "    nn.LeakyReLU(0.5),\n",
    "    nn.BatchNorm1d(49 * 3),\n",
    "\n",
    "    # shape [batch, 49 * 3]\n",
    "    Reshape((3, 7, 7)),\n",
    "    nn.ConvTranspose2d(3, 2, 4, 2, 1),\n",
    "    nn.LeakyReLU(0.5),\n",
    "    nn.BatchNorm2d(2),\n",
    "\n",
    "    # shape [batch, 2, 14, 14]\n",
    "    nn.ConvTranspose2d(2, 1, 4, 2, 1),\n",
    "    \n",
    "    # shape [batch, 1, 28, 28]\n",
    "    Reshape((28, 28)),\n",
    "    nn.Tanh(),\n",
    ").to(device)\n",
    "\n",
    "\n",
    "discriminator = nn.Sequential(\n",
    "    Reshape((1, 28, 28)),\n",
    "    nn.Conv2d(1, 2, 4, 2, 1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(2),\n",
    "\n",
    "    # shape [batch, 2, 14, 14]\n",
    "    nn.Conv2d(2, 3, 4, 2, 1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(3),\n",
    "\n",
    "    # shape [batch, 3, 7, 7]\n",
    "    nn.Flatten(),\n",
    "\n",
    "    # shape [batch, 3 * 7 * 7]\n",
    "    nn.Linear(3 * 7 * 7, 1),\n",
    "    nn.Sigmoid()\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "g_optim = torch.optim.Adam(generator.parameters())\n",
    "d_optim = torch.optim.Adam(discriminator.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T14:11:34.197974Z",
     "start_time": "2020-01-28T14:02:34.645176Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "loss_crit = torch.nn.BCELoss()\n",
    "\n",
    "ones = torch.ones((batch_size, 1)).to(device)\n",
    "zeros = torch.zeros((batch_size, 1)).to(device)\n",
    "samples_z = torch.rand((batch_size, z_size)).to(device)\n",
    "\n",
    "losses = []\n",
    "num_epochs = 10\n",
    "for e in tqdm(range(num_epochs), leave=False):\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        # train the generator\n",
    "        g_optim.zero_grad()\n",
    "        z = torch.rand((batch_size, z_size)).to(device)\n",
    "        fake_imgs = generator(z)\n",
    "        g_loss = loss_crit(discriminator(fake_imgs), ones)\n",
    "        g_loss.backward(retain_graph = True)\n",
    "        g_optim.step()\n",
    "\n",
    "        # train the discriminator\n",
    "        d_optim.zero_grad()\n",
    "        d_loss = (\n",
    "            loss_crit(discriminator(images), ones)\n",
    "            + \n",
    "            loss_crit(discriminator(fake_imgs), zeros)\n",
    "        )\n",
    "        d_loss.backward()\n",
    "        d_optim.step()\n",
    "        if i % 10 == 0:\n",
    "            losses.append([g_loss.item(), d_loss.item()])\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            samples = generator(samples_z).view(-1, 1, 28, 28)\n",
    "            save_image(make_grid(samples), f\"generated/{e}_{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T14:12:33.881979Z",
     "start_time": "2020-01-28T14:12:33.660108Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "losses = np.array(losses)\n",
    "plt.plot(losses[:, 0], label='generator')\n",
    "plt.plot(losses[:, 1], label='discrimnator')\n",
    "plt.title('losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Bonus\n",
    "For the bonus, fancy stuff we would like you to program a conditional GAN. This GAN should produce the output you want. Instead of feeding your generator with just noise, you feed it with noise and label and it should generated the number you want. \n",
    "To do so, you add a label part to your Generator's input and you tell your discriminator what number it should recognize by adding a label part to your Discriminator's input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN/master/pytorch_cGAN.png\" width=\"900\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://raw.githubusercontent.com/znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN/master/pytorch_cGAN.png\", width=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
